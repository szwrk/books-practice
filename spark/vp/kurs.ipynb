{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"R2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2 \n",
    "fs & .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---+\n",
      "|first|    last|age|\n",
      "+-----+--------+---+\n",
      "|  jan|kowalski| 44|\n",
      "| adam|   nowak| 64|\n",
      "+-----+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"jan\",\"kowalski\",44),\n",
    "        (\"adam\",\"nowak\",64)\n",
    "    ],\n",
    "    [\"first\",\"last\",\"age\"]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+-------+------+\n",
      "|_c0|        _c1|   _c2|    _c3|   _c4|\n",
      "+---+-----------+------+-------+------+\n",
      "| id|       name|dep_id|exp_lvl|salary|\n",
      "|  1|     'Anna'|     1|      1|  1000|\n",
      "|  2| 'Krystyna'|     2|      2| 5000 |\n",
      "|  3|      'Jan'|     1|      1|  1000|\n",
      "|  4|     'John'|     1|      3|  7000|\n",
      "|  5|     'Paul'|     2|      3|  8000|\n",
      "|  6|    'Kumar'|     1|      3|  7000|\n",
      "+---+-----------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv1 = spark.read.format(\"csv\").load(\"emp.csv\")\n",
    "csv1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+-------+------+\n",
      "|_c0|        _c1|   _c2|    _c3|   _c4|\n",
      "+---+-----------+------+-------+------+\n",
      "| id|       name|dep_id|exp_lvl|salary|\n",
      "|  1|     'Anna'|     1|      1|  1000|\n",
      "|  2| 'Krystyna'|     2|      2| 5000 |\n",
      "|  3|      'Jan'|     1|      1|  1000|\n",
      "|  4|     'John'|     1|      3|  7000|\n",
      "|  5|     'Paul'|     2|      3|  8000|\n",
      "|  6|    'Kumar'|     1|      3|  7000|\n",
      "+---+-----------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv2 = spark.read.csv(\"emp.csv\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+-------+------+\n",
      "| id|       name|dep_id|exp_lvl|salary|\n",
      "+---+-----------+------+-------+------+\n",
      "|  1|     'Anna'|     1|      1|  1000|\n",
      "|  2| 'Krystyna'|     2|      2| 5000 |\n",
      "|  3|      'Jan'|     1|      1|  1000|\n",
      "|  4|     'John'|     1|      3|  7000|\n",
      "|  5|     'Paul'|     2|      3|  8000|\n",
      "|  6|    'Kumar'|     1|      3|  7000|\n",
      "+---+-----------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv3 = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(header=True, sep=\",\")\n",
    "    .load(\"emp.csv\")\n",
    ")\n",
    "csv3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**csv ver1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "| ROK|MIESIAC|OW_NFZ|NIP_PODMIOTU|KOD_PRODUKTU_KONTRAKTOWEGO|KOD_PRODUKTU_JEDNOSTKOWEGO|KOD_TRYBU_PRZYJECIA|KOD_TRYBU_WYPISU|PLEC_PACJENTA|GRUPA_WIEKOWA_PACJENTA|PRZEDZIAL_DLUGOSCI_TRWANIA_HOSPITALIZACJI|LICZBA_HOSPITALIZACJI|\n",
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "|2022|      4|    07|  1132866688|            03.4580.991.02|           5.51.01.0008013|                  6|               2|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      8|    02|  5562239217|            03.4220.030.02|           5.51.01.0001087|                  3|               2|            K|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|      1|    07|  7742411908|            03.4500.030.02|           5.51.01.0017007|                  2|               9|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      9|    03|  7122409395|            03.4500.030.02|           5.51.01.0008083|                  3|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|     11|    03|  9462146139|            03.4580.991.02|           5.51.01.0008015|                  6|               2|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      9|    15|  7842008454|            03.4450.040.02|           5.51.01.0012014|                  3|               2|            K|           65 i więcej|                                    0 dni|                   <5|\n",
      "|2022|      4|    13|  6572195982|            03.4500.030.02|           5.51.01.0006109|                  6|               2|            K|           65 i więcej|                                  3-5 dni|                   <5|\n",
      "|2022|      1|    11|  5832580921|            03.4580.030.02|           5.51.01.0008099|                  6|               2|            K|                 45-64|                                  1-2 dni|                   <5|\n",
      "|2022|      9|    07|  1181417683|            03.4401.030.02|           5.51.01.0014004|                  3|               2|            K|                  0-17|                                  1-2 dni|                   <5|\n",
      "|2022|      7|    07|  7742411908|            03.4000.030.02|           5.51.01.0016056|                  3|               1|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|     12|    15|  7642088098|            03.4220.130.02|           5.51.01.0001048|                  2|               9|            M|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      6|    05|  8361081857|            03.4500.030.02|           5.51.01.0006072|                  6|               2|            K|                 18-44|                                  3-5 dni|                   <5|\n",
      "|2022|      4|    07|  8212056050|            03.4340.030.02|           5.51.01.0004018|                  2|               1|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      3|    13|  9591294907|            03.4250.030.02|           5.51.01.0006103|                  6|               2|            K|           65 i więcej|                                  1-2 dni|                   <5|\n",
      "|2022|      7|    09|  7921805707|            03.4401.030.02|           5.51.01.0014003|                  3|               1|            K|                  0-17|                                  3-5 dni|                   <5|\n",
      "|2022|     10|    06|  6772247459|            03.4100.030.02|           5.51.01.0005032|                  6|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|      4|    08|  7471571941|            03.4000.030.02|           5.51.01.0004028|                  3|               1|            M|           65 i więcej|                                  3-5 dni|                   <5|\n",
      "|2022|      7|    15|  7811619837|            03.4150.030.02|           5.51.01.0016062|                  8|               3|            M|                 18-44|                                  3-5 dni|                   <5|\n",
      "|2022|      9|    01|  9121650658|            03.4000.030.02|           5.51.01.0006036|                  6|               2|            M|                 45-64|                                  1-2 dni|                   <5|\n",
      "|2022|     10|    02|  8741484403|            03.4000.030.02|           5.51.01.0005094|                  3|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv4 = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(header=True, sep=\";\")\n",
    "    .load(\"hosp2022.csv\")\n",
    ")\n",
    "csv4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**csv ver2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "| ROK|MIESIAC|OW_NFZ|NIP_PODMIOTU|KOD_PRODUKTU_KONTRAKTOWEGO|KOD_PRODUKTU_JEDNOSTKOWEGO|KOD_TRYBU_PRZYJECIA|KOD_TRYBU_WYPISU|PLEC_PACJENTA|GRUPA_WIEKOWA_PACJENTA|PRZEDZIAL_DLUGOSCI_TRWANIA_HOSPITALIZACJI|LICZBA_HOSPITALIZACJI|\n",
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "|2022|      4|    07|  1132866688|            03.4580.991.02|           5.51.01.0008013|                  6|               2|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      8|    02|  5562239217|            03.4220.030.02|           5.51.01.0001087|                  3|               2|            K|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|      1|    07|  7742411908|            03.4500.030.02|           5.51.01.0017007|                  2|               9|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      9|    03|  7122409395|            03.4500.030.02|           5.51.01.0008083|                  3|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|     11|    03|  9462146139|            03.4580.991.02|           5.51.01.0008015|                  6|               2|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      9|    15|  7842008454|            03.4450.040.02|           5.51.01.0012014|                  3|               2|            K|           65 i więcej|                                    0 dni|                   <5|\n",
      "|2022|      4|    13|  6572195982|            03.4500.030.02|           5.51.01.0006109|                  6|               2|            K|           65 i więcej|                                  3-5 dni|                   <5|\n",
      "|2022|      1|    11|  5832580921|            03.4580.030.02|           5.51.01.0008099|                  6|               2|            K|                 45-64|                                  1-2 dni|                   <5|\n",
      "|2022|      9|    07|  1181417683|            03.4401.030.02|           5.51.01.0014004|                  3|               2|            K|                  0-17|                                  1-2 dni|                   <5|\n",
      "|2022|      7|    07|  7742411908|            03.4000.030.02|           5.51.01.0016056|                  3|               1|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|     12|    15|  7642088098|            03.4220.130.02|           5.51.01.0001048|                  2|               9|            M|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      6|    05|  8361081857|            03.4500.030.02|           5.51.01.0006072|                  6|               2|            K|                 18-44|                                  3-5 dni|                   <5|\n",
      "|2022|      4|    07|  8212056050|            03.4340.030.02|           5.51.01.0004018|                  2|               1|            K|           65 i więcej|                           6 i więcej dni|                   <5|\n",
      "|2022|      3|    13|  9591294907|            03.4250.030.02|           5.51.01.0006103|                  6|               2|            K|           65 i więcej|                                  1-2 dni|                   <5|\n",
      "|2022|      7|    09|  7921805707|            03.4401.030.02|           5.51.01.0014003|                  3|               1|            K|                  0-17|                                  3-5 dni|                   <5|\n",
      "|2022|     10|    06|  6772247459|            03.4100.030.02|           5.51.01.0005032|                  6|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "|2022|      4|    08|  7471571941|            03.4000.030.02|           5.51.01.0004028|                  3|               1|            M|           65 i więcej|                                  3-5 dni|                   <5|\n",
      "|2022|      7|    15|  7811619837|            03.4150.030.02|           5.51.01.0016062|                  8|               3|            M|                 18-44|                                  3-5 dni|                   <5|\n",
      "|2022|      9|    01|  9121650658|            03.4000.030.02|           5.51.01.0006036|                  6|               2|            M|                 45-64|                                  1-2 dni|                   <5|\n",
      "|2022|     10|    02|  8741484403|            03.4000.030.02|           5.51.01.0005094|                  3|               2|            M|                 45-64|                           6 i więcej dni|                   <5|\n",
      "+----+-------+------+------------+--------------------------+--------------------------+-------------------+----------------+-------------+----------------------+-----------------------------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv5 = spark.read.csv(\"hosp2022.csv\", header=True, sep=\";\")\n",
    "csv5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display df schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "|                Name|Sales in Milions|              Series|Release|               Genre|           Developer|           Publisher|\n",
      "+--------------------+----------------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "|PlayerUnknown's B...|              42|                NULL| Dec-17|       Battle royale|        PUBG Studios|             Krafton|\n",
      "|           Minecraft|              33|                NULL| Nov-11|             Sandbox|      Mojang Studios|      Mojang Studios|\n",
      "|          Diablo III|              30|              Diablo| May-12| Action role-playing|Blizzard Entertai...|Blizzard Entertai...|\n",
      "|         Garry's Mod|              20|                NULL| Nov-06|             Sandbox|   Facepunch Studios|               Valve|\n",
      "|            Terraria|            17.2|                NULL| May-11|    Action-adventure|            Re-Logic|            Re-Logic|\n",
      "|   World of Warcraft|              14|            Warcraft| Nov-04|              MMORPG|Blizzard Entertai...|Blizzard Entertai...|\n",
      "|         Half-Life 2|              12|           Half-Life| Nov-04|First-person shooter|               Valve|     Valve (digital)|\n",
      "|The Witcher 3: Wi...|              11|         The Witcher| May-15| Action role-playing|      CD Projekt Red|          CD Projekt|\n",
      "|           StarCraft|              11|           StarCraft| Mar-98|  Real-time strategy|Blizzard Entertai...|Blizzard Entertai...|\n",
      "|            The Sims|              11|            The Sims| Feb-00|     Life simulation|               Maxis|     Electronic Arts|\n",
      "|           Fall Guys|              11|                NULL| Aug-20|       Battle royale|          Mediatonic|    Devolver Digital|\n",
      "|RollerCoaster Tyc...|              10|RollerCoaster Tycoon| Oct-04|Construction and ...|Frontier Developm...|               Atari|\n",
      "|           Half-Life|               9|           Half-Life| Nov-98|First-person shooter|               Valve|Sierra Entertainment|\n",
      "|                Rust|               9|                NULL| Feb-18|            Survival|   Facepunch Studios|   Facepunch Studios|\n",
      "|     Civilization VI|               8|        Civilization| Sep-10| Turn-based strategy|                  4X|       Firaxis Games|\n",
      "+--------------------+----------------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"R2\").getOrCreate()\n",
    "df = spark.read.csv(\"games.csv\", header=True, quote=\"\\\"\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales in Milions: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- Release: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Developer: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('Book', StringType(), False), StructField('Authors', StringType(), False), StructField('Original', StringType(), False), StructField('Sales', IntegerType(), False)])\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"Book\", StringType(), False),\n",
    "        StructField(\"Authors\", StringType(), False),\n",
    "        StructField(\"Original\", StringType(), False),\n",
    "        StructField(\"Sales\", IntegerType(), False)\n",
    "    ]\n",
    ")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------+-----+\n",
      "|                Book|Authors|Original|Sales|\n",
      "+--------------------+-------+--------+-----+\n",
      "|PlayerUnknown's B...|     42|    NULL| NULL|\n",
      "|           Minecraft|     33|    NULL| NULL|\n",
      "|          Diablo III|     30|  Diablo| NULL|\n",
      "|         Garry's Mod|     20|    NULL| NULL|\n",
      "|            Terraria|   17.2|    NULL| NULL|\n",
      "+--------------------+-------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/12 01:23:15 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 4\n",
      "CSV file: file:///mnt/c/Users/Arek/Documents/_PROJEKTY/data_practice/spark/vp/games.csv\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"games.csv\", header=True, schema=schema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Book: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Original: string (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"Name\", StringType(),False),\n",
    "        StructField(\"LastName\", StringType(),False),\n",
    "        StructField(\"Age\", IntegerType(),False)            \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+\n",
      "|Name|LastName|Age|\n",
      "+----+--------+---+\n",
      "| jan|kowalski| 44|\n",
      "|adam|   nowak| 64|\n",
      "+----+--------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"jan\",\"kowalski\",44),\n",
    "        (\"adam\",\"nowak\",64)\n",
    "    ],\n",
    "    schema\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "| jan| 44|\n",
      "|adam| 64|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"Name\"), col(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "| jan| 44|\n",
      "|adam| 64|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\",\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|adam| 64|\n",
      "| jan| 44|\n",
      "+----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sorted = df.select(col(\"Name\"), col(\"Age\")).orderBy(col(\"Age\").desc())\n",
    "df_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## limit & collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|adam|64 |\n",
      "+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sorted.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**truncate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----+\n",
      "|                Name|LastName| Age|\n",
      "+--------------------+--------+----+\n",
      "|PlayerUnknown's B...|      42|NULL|\n",
      "+--------------------+--------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/12 01:40:42 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 3\n",
      "CSV file: file:///mnt/c/Users/Arek/Documents/_PROJEKTY/data_practice/spark/vp/games.csv\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"games.csv\", header=True, schema=schema)\n",
    "df.show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+--------+----+\n",
      "|Name                         |LastName|Age |\n",
      "+-----------------------------+--------+----+\n",
      "|PlayerUnknown's Battlegrounds|42      |NULL|\n",
      "+-----------------------------+--------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/12 01:40:42 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 3\n",
      "CSV file: file:///mnt/c/Users/Arek/Documents/_PROJEKTY/data_practice/spark/vp/games.csv\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**limit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|adam| 64|\n",
      "+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sorted.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|adam| 64|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sorted.limit(1).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**collect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='adam', Age=64)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**collect - get first row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='adam', Age=64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(1).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**collect -get row, get column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"R3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PlayerUnknown's Battlegrounds\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\"games.csv\", header=True)\n",
    "df.limit(1).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be careful with collect! (RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+------+-------+-------------+------------+---------+\n",
      "|                Name|Sales in Milions|Series|Release|        Genre|   Developer|Publisher|\n",
      "+--------------------+----------------+------+-------+-------------+------------+---------+\n",
      "|PlayerUnknown's B...|              42|  NULL| Dec-17|Battle royale|PUBG Studios|  Krafton|\n",
      "+--------------------+----------------+------+-------+-------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|Sales in Milions|NewColumn|\n",
      "+----------------+---------+\n",
      "|              42|     84.0|\n",
      "|              33|     66.0|\n",
      "|              30|     60.0|\n",
      "+----------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.withColumn(\"NewColumn\", col(\"Sales in milions\") * 2 ).select(col(\"Sales in Milions\"), col(\"NewColumn\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|Sales in Milions|NewColumn|\n",
      "+----------------+---------+\n",
      "|              42|     84.0|\n",
      "|              33|     66.0|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limited_df = df.withColumn(\"NewColumn\", col(\"Sales in milions\") * 2 ).limit(2).select(col(\"Sales in Milions\"), col(\"NewColumn\"))\n",
    "limited_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sales in Milions='42', NewColumn=84.0),\n",
       " Row(Sales in Milions='33', NewColumn=66.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Sales in Milions': '42', 'NewColumn': 84.0},\n",
       " {'Sales in Milions': '33', 'NewColumn': 66.0}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row.asDict() for row in limited_df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Sales in Milions='42', NewColumn=84.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_df.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_df.collect()[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddbdc7",
   "metadata": {},
   "source": [
    "## Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType\n",
    "spark = SparkSession.builder.appName(\"App2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+\n",
      "|col1|        first|              second|\n",
      "+----+-------------+--------------------+\n",
      "|   a|[test, test2]|{1 -> test3, 3 ->...|\n",
      "|   b|   [foo, bar]| {4 -> qx, 2 -> baz}|\n",
      "+----+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(    \n",
    "    [\n",
    "        StructField(\"col1\",StringType(),False),\n",
    "        StructField(\"first\", ArrayType(StringType()), False),\n",
    "        StructField(\"second\",MapType(IntegerType(), StringType()), False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "data =  [\n",
    "       (\n",
    "           \"a\",\n",
    "       [\"test\", \"test2\"],\n",
    "       {1: \"test3\", 3: \"test4\"}\n",
    "       ),\n",
    "       (\n",
    "           \"b\",\n",
    "           [\"foo\",\"bar\"],\n",
    "           {2:\"baz\", 4:\"qx\"}\n",
    "       )\n",
    "    ]\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'test2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    ".collect() \\\n",
    "[0] \\\n",
    "[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'test2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "df \n",
    ".collect()\n",
    "[0]\n",
    "[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "df \n",
    ".collect() # get RDD data\n",
    "[0] # get first row\n",
    "[\"col1\"] # get column value by name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "df\n",
    ".collect() # 1 get data from Spark RDD and load to memory 2. convert and return as List[Row]\n",
    "[0]\n",
    "[\"col1\"] # get column value by name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|col1|\n",
      "+----+\n",
      "|   a|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.col1 == \"a\").select(\"col1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get item, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import size\n",
    "schema = StructType(    \n",
    "    [\n",
    "        StructField(\"col1\",StringType(),False),\n",
    "        StructField(\"first\", ArrayType(StringType()), False),\n",
    "        StructField(\"second\",MapType(IntegerType(), StringType()), False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "data =  [\n",
    "       (\n",
    "           \"a\",\n",
    "       [\"test\", \"test2\"],\n",
    "       {1: \"test3\", 3: \"test4\"}\n",
    "       ),\n",
    "       (\n",
    "           \"b\",\n",
    "           [\"foo\",\"bar\"],\n",
    "           {2:\"baz\", 4:\"qx\"}\n",
    "       )\n",
    "    ]\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|first[0]|\n",
      "+--------+\n",
      "|    test|\n",
      "|     foo|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "        col(\"first\").getItem(0)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "| sec|size(second)|\n",
      "+----+------------+\n",
      "|NULL|           2|\n",
      "| baz|           2|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "        col(\"second\").getItem(2).alias(\"sec\"),\n",
    "        size(col(\"second\"))\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (WSL)",
   "language": "python",
   "name": "pyspark-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
